services:

  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.33.1
    command: "--host 0.0.0.0 --port '8081' --scheme http"
    ports:
      - "8081:8081"
      - "50051:50051"
    volumes:
      - ./include/weaviate/backup:/var/lib/weaviate/backup
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_APIKEY_ENABLED: 'true'
      AUTHENTICATION_APIKEY_ALLOWED_KEYS: 'readonlykey,adminkey'
      AUTHENTICATION_APIKEY_USERS: 'jane@doe.com,john@doe.com'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'
      ENABLE_MODULES: 'text2vec-openai, backup-filesystem, qna-openai, text2vec'
      BACKUP_FILESYSTEM_PATH: '/var/lib/weaviate/backup'
      CLUSTER_HOSTNAME: 'node1'
    networks:
      - airflow

  kafka:
    image: confluentinc/cp-kafka
    ports:
      - "9092:9092"
      - "19092:19092"
    environment:
      # KRaft mode configuration
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Listener configuration
      KAFKA_LISTENERS: PLAINTEXT://kafka:9092,CONTROLLER://kafka:29093,DOCKER_HACK://kafka:19092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,DOCKER_HACK://kafka:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,DOCKER_HACK:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # Topic and replication settings
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

      # Cluster and log settings
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    volumes:
      - /tmp/kraft-combined-logs:/tmp/kraft-combined-logs
    command: >
      sh -c "
      kafka-storage format -t $${CLUSTER_ID} -c /etc/kafka/kafka.properties --ignore-formatted || true &&
      /etc/confluent/docker/run &
      sleep 30 &&
      kafka-topics --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic my_topic || true &&
      kafka-topics --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic incident_channel || true &&
      wait
      "
    networks:
      - airflow
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "kafka:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5

  scheduler:
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - airflow

  triggerer:
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - airflow


networks:
  airflow:
    driver: bridge